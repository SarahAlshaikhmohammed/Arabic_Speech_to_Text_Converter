{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Arabic Speech to Text Converter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install Necessary Libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pydub pytube speechrecognition google-cloud-storage ffmpeg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "import speech_recognition as sr\n",
    "from pydub import AudioSegment\n",
    "from pydub.silence import split_on_silence\n",
    "from pytube import YouTube\n",
    "import pandas as pd\n",
    "\n",
    "# Initialize the recognizer\n",
    "r = sr.Recognizer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to Transcribe Audio from File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transcribe_audio(path, language='ar'):\n",
    "    \"\"\"\n",
    "    Transcribe audio from a file and returns the transcribed text.\n",
    "    \n",
    "    Parameters:\n",
    "    - path (str): Path to the audio file\n",
    "    - language (str): Language of the audio for transcription (default is 'ar' for Arabic)\n",
    "    \n",
    "    Returns:\n",
    "    - text (str): Transcribed text\n",
    "    \"\"\"\n",
    "    with sr.AudioFile(path) as source:  # Open the audio file\n",
    "        audio_listened = r.record(source)  # Record the audio\n",
    "        text = r.recognize_google(audio_listened, language=language)  # Transcribe the audio using Google's API\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to Split Audio into Chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_audio_chunks(sound, silence_len=500, silence_thresh=-14, keep_silence=500):\n",
    "    \"\"\"\n",
    "    Split audio into chunks based on silence and returns list of audio chunks.\n",
    "    \n",
    "    Parameters:\n",
    "    - sound (AudioSegment): The audio segment to be split\n",
    "    - silence_len (int): Minimum length of silence to consider for splitting (in ms)\n",
    "    - silence_thresh (int): Silence threshold in dBFS\n",
    "    - keep_silence (int): Amount of silence to leave at the beginning and end of each chunk (in ms)\n",
    "    \n",
    "    Returns:\n",
    "    - List of audio chunks\n",
    "    \"\"\"\n",
    "    return split_on_silence(sound,\n",
    "                            min_silence_len=silence_len,\n",
    "                            silence_thresh=sound.dBFS + silence_thresh,\n",
    "                            keep_silence=keep_silence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to Process Audio Chunks and Concatenate Transcriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_chunks(chunks, folder_name, language='ar'):\n",
    "    \"\"\"\n",
    "    Process audio chunks, transcribe them, and concatenate the transcribed text as final output.\n",
    "    \n",
    "    Parameters:\n",
    "    - chunks (list): List of audio chunks\n",
    "    - folder_name (str): Folder where chunks will be saved\n",
    "    - language (str): Language for transcription\n",
    "    \n",
    "    Returns:\n",
    "    - whole_text (str): Full transcription of all audio chunks\n",
    "    \"\"\"\n",
    "    if not os.path.isdir(folder_name):  # Create the folder if it doesn't exist\n",
    "        os.mkdir(folder_name)\n",
    "\n",
    "    whole_text = \"Complete Transcription: \"\n",
    "    for i, audio_chunk in enumerate(chunks, start=1):  # Iterate through each audio chunk\n",
    "        chunk_filename = os.path.join(folder_name, f\"chunk{i}.wav\")  # Define the chunk file path\n",
    "        audio_chunk.export(chunk_filename, format=\"wav\")  # Export the chunk as a wav file\n",
    "\n",
    "        try:\n",
    "            text = transcribe_audio(chunk_filename, language)  # Transcribe the audio chunk\n",
    "        except sr.UnknownValueError:\n",
    "            print(\"\")  # Handle transcription errors gracefully\n",
    "        else:\n",
    "            text = f\"{text.capitalize()}. \"  # Capitalize and format the transcribed text\n",
    "            whole_text += text  # Append the transcribed text to the whole text\n",
    "\n",
    "    return whole_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to Transcribe Large Audio Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_large_audio_transcription(path, method='silence', interval=5, language='ar'):\n",
    "    \"\"\"\n",
    "    Transcribe a large audio file by splitting it into chunks.\n",
    "    \n",
    "    Parameters:\n",
    "    - path (str): Path to the audio file\n",
    "    - method (str): Method for splitting audio ('silence' or 'interval')\n",
    "    - interval (int): Interval in minutes for splitting the audio (used if method is 'interval')\n",
    "    - language (str): Language for transcription\n",
    "    \n",
    "    Returns:\n",
    "    - Final transcribed text\n",
    "    \"\"\"\n",
    "    sound = AudioSegment.from_file(path)  # Load the audio file\n",
    "\n",
    "    # Split the audio based on the selected method\n",
    "    if method == 'silence':\n",
    "        chunks = split_audio_chunks(sound)  # Split by silence\n",
    "    else:\n",
    "        chunk_length_ms = interval * 60 * 1000  # Convert interval to milliseconds\n",
    "        chunks = [sound[i:i + chunk_length_ms] for i in range(0, len(sound), chunk_length_ms)]  # Split by fixed intervals\n",
    "\n",
    "    folder_name = \"audio-chunks\" if method == 'silence' else \"audio-fixed-chunks\"  # Define folder name based on method\n",
    "    return process_chunks(chunks, folder_name, language)  # Process and transcribe the chunks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transcribe the Audio File and Save Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    downloaded_file = \"/path/to/audio.wav\"  # Path to the audio file\n",
    "\n",
    "    # Transcribe the audio file using silence-based chunking\n",
    "    transcription = get_large_audio_transcription(downloaded_file, method='silence')\n",
    "    print(transcription)  # Print the full transcription\n",
    "\n",
    "    # Convert the transcription to a DataFrame with a single column\n",
    "    transcription_df = pd.DataFrame([transcription], columns=['Transcription'])\n",
    "    transcription_df  # Display the DataFrame\n",
    "\n",
    "    # Count words in the transcription\n",
    "    def count_words(text):\n",
    "        words = text.split()\n",
    "        return len(words)\n",
    "\n",
    "    word_count = count_words(transcription)\n",
    "    print(\"Number of Words:\", word_count)\n",
    "\n",
    "    # Save the transcription to a CSV file\n",
    "    transcription_df.to_csv('text.txt')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
